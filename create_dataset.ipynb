{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPTP Formatting\n",
    "fof(name,formula_type,statement)\n",
    "- name is the name of the formula\n",
    "- formula_type is either axiom or conjecture, for our purposes.\n",
    "- Axioms are facts\n",
    "- Conjectures are what we want to prove/disprove\n",
    "\n",
    "\n",
    "Extra TPTP notes:\n",
    "- ! is the universal quantifier\n",
    "- ? is the existential quantifier\n",
    "- variables are denoted with capital letters\n",
    "- func(C) is a function with variable C\n",
    "- => is the implication operator\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NEGATION\n",
    "- <=> is EQUIVALENCE\n",
    "- = is EQUALITY\n",
    "- != is INEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axiom:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",axiom,\"+str(self.statement)+\").\"\n",
    "\n",
    "class Conjecture:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",conjecture,\"+str(self.statement)+\").\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNF creation\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NOT\n",
    "- CNF -> (Disjunction) & CNF\n",
    "- CNF -> (Disjunction)\n",
    "- Disjunction -> Literal | Disjunction\n",
    "- Disjunction -> Literal\n",
    "- Literal -> ~Variable\n",
    "- Literal -> Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "420\n"
     ]
    }
   ],
   "source": [
    "def produce_disjunctions(literal_list):\n",
    "    disjunction_dict = dict()\n",
    "    disjunction_dict_old = dict()\n",
    "    disjunction_list = []\n",
    "\n",
    "    for l in literal_list:\n",
    "        disjunction_dict[str(l)]=l\n",
    "        disjunction_dict_old[str(l)]=l\n",
    "\n",
    "    for key in disjunction_dict_old:\n",
    "        for l in literal_list:\n",
    "            disjunction_dict[str(l)+'|'+str(disjunction_dict_old[key])]=str(l)+' | '+str(disjunction_dict_old[key])\n",
    "\n",
    "    for key in disjunction_dict:\n",
    "        disjunction_list.append(disjunction_dict[key])\n",
    "\n",
    "    disjunction_dict = None\n",
    "    disjunction_dict_old = None\n",
    "    \n",
    "    return disjunction_list\n",
    "\n",
    "def produce_cnf(disjunction_list):\n",
    "    cnf_dict_new = dict()\n",
    "    cnf_list_old = []\n",
    "    cnf_list_new = []\n",
    "\n",
    "    for d in disjunction_list:\n",
    "        cnf_list_old.append(' ( '+str(d)+' ) ')\n",
    "        cnf_dict_new['('+str(d)+')']=' ( '+str(d)+' ) '\n",
    "\n",
    "    for c in cnf_list_old:\n",
    "        for d in disjunction_list:\n",
    "            cnf_dict_new['('+str(d)+')&'+str(c)]=' ( '+str(d)+' ) & '+str(c)\n",
    "    \n",
    "    for key in cnf_dict_new:\n",
    "        cnf_list_new.append(cnf_dict_new[key])\n",
    "\n",
    "    cnf_list_old = None\n",
    "    cnf_dict_new = None\n",
    "\n",
    "    return cnf_list_new\n",
    "\n",
    "#variable_list = ['a','b','c', 'd', 'e']\n",
    "variable_list = ['a','b']\n",
    "literal_list = []\n",
    "disjunction_list = []\n",
    "\n",
    "\n",
    "for var in variable_list:\n",
    "    for i in range(2):\n",
    "        if i % 2 == 0:\n",
    "            literal_list.append(str(var))\n",
    "        else:\n",
    "            literal_list.append('~'+str(var))\n",
    "\n",
    "d_list = produce_disjunctions(literal_list)\n",
    "cnf_list = produce_cnf(d_list)\n",
    "print(len(d_list))\n",
    "print(len(cnf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list()\n",
    "conclusions = list()\n",
    "for e in cnf_list:\n",
    "    statements.append(e)\n",
    "    conclusions.append(e)\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append([Axiom(str(i),statements[i]),statements[i]])\n",
    "\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append([Conjecture(str(i),conclusions[i]),conclusions[i]])\n",
    "\n",
    "theorum_list = list()\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        input = str(s[0])+str(c[0])\n",
    "        plain_text = str(s[1])+\" => \"+str(c[1])\n",
    "        theorum_list.append([input,plain_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use E to find proofs (or non-proofs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "for t in theorum_list:\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(t[0]))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        found_proofs.append([str(t[0]),result,t[1]])\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(t[0]),result,t[1]])\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Training data.\n",
    "- True indicates a found proof.\n",
    "- False indicates no proof found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_training_data(found, unfound):\n",
    "    input = []\n",
    "    for sample in found:\n",
    "        s = sample[2]\n",
    "        input.append([s,True])\n",
    "\n",
    "    for sample in unfound:\n",
    "        s = sample[2]\n",
    "        input.append([s,False])\n",
    "    \n",
    "    return input\n",
    "\n",
    "training_data = format_training_data(found_proofs,unfound_proofs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the input\n",
    "fof(368,axiom,(a|~a)&(~a|~b)).fof(131,conjecture,(~b|~a)&(~a|a)).\n",
    "\n",
    "should be \n",
    "\n",
    "(a|~a)&(~a|~b) => (~b|~a)&(~a|a)\n",
    "\n",
    "token list:\n",
    "(\n",
    ")\n",
    "a\n",
    "|\n",
    "~\n",
    "b\n",
    "=>\n",
    "&\n",
    "\n",
    "write the tokenization, input that into a LSTM to classify theorums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_data.pickle','wb') as f:\n",
    "    pickle.dump(training_data,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
