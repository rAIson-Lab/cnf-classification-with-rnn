{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPTP Formatting\n",
    "fof(name,formula_type,statement)\n",
    "- name is the name of the formula\n",
    "- formula_type is either axiom or conjecture, for our purposes.\n",
    "- Axioms are facts\n",
    "- Conjectures are what we want to prove/disprove\n",
    "\n",
    "\n",
    "Extra TPTP notes:\n",
    "- ! is the universal quantifier\n",
    "- ? is the existential quantifier\n",
    "- variables are denoted with capital letters\n",
    "- func(C) is a function with variable C\n",
    "- => is the implication operator\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NEGATION\n",
    "- <=> is EQUIVALENCE\n",
    "- = is EQUALITY\n",
    "- != is INEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axiom:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",axiom,\"+str(self.statement)+\").\"\n",
    "\n",
    "class Conjecture:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",conjecture,\"+str(self.statement)+\").\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNF creation\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NOT\n",
    "- CNF -> (Disjunction) & CNF\n",
    "- CNF -> (Disjunction)\n",
    "- Disjunction -> Literal | Disjunction\n",
    "- Disjunction -> Literal\n",
    "- Literal -> ~Variable\n",
    "- Literal -> Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_disjunctions(literal_list):\n",
    "    disjunction_dict = dict()\n",
    "    disjunction_dict_old = dict()\n",
    "    disjunction_list = []\n",
    "\n",
    "    for l in literal_list:\n",
    "        disjunction_dict[str(l)]=l\n",
    "        disjunction_dict_old[str(l)]=l\n",
    "\n",
    "    for key in disjunction_dict_old:\n",
    "        for l in literal_list:\n",
    "            disjunction_dict[str(l)+'|'+str(disjunction_dict_old[key])]=str(l)+'|'+str(disjunction_dict_old[key])\n",
    "\n",
    "    for key in disjunction_dict:\n",
    "        disjunction_list.append(disjunction_dict[key])\n",
    "\n",
    "    disjunction_dict = None\n",
    "    disjunction_dict_old = None\n",
    "    \n",
    "    return disjunction_list\n",
    "\n",
    "def produce_cnf(disjunction_list):\n",
    "    cnf_dict_new = dict()\n",
    "    cnf_list_old = []\n",
    "    cnf_list_new = []\n",
    "\n",
    "    for d in disjunction_list:\n",
    "        cnf_list_old.append('('+str(d)+')')\n",
    "        cnf_dict_new['('+str(d)+')']='('+str(d)+')'\n",
    "\n",
    "    for c in cnf_list_old:\n",
    "        for d in disjunction_list:\n",
    "            cnf_dict_new['('+str(d)+')&'+str(c)]='('+str(d)+')&'+str(c)\n",
    "    \n",
    "    for key in cnf_dict_new:\n",
    "        cnf_list_new.append(cnf_dict_new[key])\n",
    "\n",
    "    cnf_list_old = None\n",
    "    cnf_dict_new = None\n",
    "\n",
    "    return cnf_list_new\n",
    "\n",
    "#variable_list = ['a','b','c', 'd', 'e']\n",
    "variable_list = ['a','b']\n",
    "literal_list = []\n",
    "disjunction_list = []\n",
    "\n",
    "\n",
    "for var in variable_list:\n",
    "    for i in range(2):\n",
    "        if i % 2 == 0:\n",
    "            literal_list.append(str(var))\n",
    "        else:\n",
    "            literal_list.append('~'+str(var))\n",
    "\n",
    "d_list = produce_disjunctions(literal_list)\n",
    "cnf_list = produce_cnf(d_list)\n",
    "print(len(d_list))\n",
    "print(len(cnf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list()\n",
    "conclusions = list()\n",
    "for e in cnf_list:\n",
    "    statements.append(e)\n",
    "    conclusions.append(e)\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append([Axiom(str(i),statements[i]),statements[i]])\n",
    "\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append([Conjecture(str(i),conclusions[i]),conclusions[i]])\n",
    "\n",
    "theorum_list = list()\n",
    "theorum_list2 = list()\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        input = str(s[0])+str(c[0])\n",
    "        plain_text = str(s[1])+\".>\"+str(c[1])+\".\"\n",
    "        theorum_list.append([input,plain_text])\n",
    "\n",
    "for s1 in statement_list:\n",
    "    for s2 in statement_list:\n",
    "        if s1 is not s2:\n",
    "            for c in conclusion_list:\n",
    "                input =  str(s1[0])+str(s2[0])+str(c[0])\n",
    "                plain_text = str(s1[1])+\".\"+str(s2[1])+\".>\"+str(c[1])+\".\"\n",
    "                theorum_list2.append([input,plain_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(theorum_list))\n",
    "print(len(theorum_list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use E to find proofs (or non-proofs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "\n",
    "for i in range(len(theorum_list)):\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(theorum_list[i][0]))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        found_proofs.append([str(theorum_list[i][0]),result,theorum_list[i][1]])\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(theorum_list[i][0]),result,theorum_list[i][1]])\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Training data.\n",
    "- \"Found\" indicates a found proof.\n",
    "- \"Unfound\" indicates no proof found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_training_data(found, unfound):\n",
    "    input = []\n",
    "    theorum = []\n",
    "    non_theorum = []\n",
    "    for sample in found:\n",
    "        s = sample[2]\n",
    "        r = \"Found\"\n",
    "        input.append([s,r])\n",
    "        theorum.append([s,r])\n",
    "\n",
    "    for sample in unfound:\n",
    "        s = sample[2]\n",
    "        r = \"Unfound\"\n",
    "        input.append([s,r])\n",
    "        non_theorum.append([s,r])\n",
    "    \n",
    "    return [input, theorum, non_theorum]\n",
    "\n",
    "training_data,found,unfound = format_training_data(found_proofs,unfound_proofs)\n",
    "\n",
    "with open('training_data.pickle','wb') as f:\n",
    "    pickle.dump(training_data,f)\n",
    "\n",
    "with open('theorum.pickle','wb') as f:\n",
    "    pickle.dump(found,f)\n",
    "\n",
    "with open('non_theorum.pickle','wb') as f:\n",
    "    pickle.dump(unfound,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_proofs2 = list()\n",
    "unfound_proofs2 = list()\n",
    "\n",
    "random.shuffle(theorum_list2)\n",
    "for i in range(len(theorum_list2)//500):\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(theorum_list2[i][0]))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        found_proofs2.append([str(theorum_list2[i][0]),result,theorum_list2[i][1]])\n",
    "        print(output)\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs2.append([str(theorum_list2[i][0]),result,theorum_list2[i][1]])\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data,found,unfound = format_training_data(found_proofs2,unfound_proofs2)\n",
    "\n",
    "with open('training_data_v2.pickle','wb') as f:\n",
    "    pickle.dump(training_data,f)\n",
    "\n",
    "with open('theorum_v2.pickle','wb') as f:\n",
    "    pickle.dump(found,f)\n",
    "\n",
    "with open('non_theorum_v2.pickle','wb') as f:\n",
    "    pickle.dump(unfound,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theorum.pickle','rb') as f:\n",
    "    theorum_data = pickle.load(f)\n",
    "\n",
    "with open('non_theorum.pickle','rb') as f:\n",
    "    non_theorum_data = pickle.load(f)\n",
    "\n",
    "print(theorum_data[-500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
