{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPTP Formatting\n",
    "fof(name,formula_type,statement)\n",
    "- name is the name of the formula\n",
    "- formula_type is either axiom or conjecture, for our purposes.\n",
    "- Axioms are facts\n",
    "- Conjectures are what we want to prove/disprove\n",
    "\n",
    "\n",
    "Extra TPTP notes:\n",
    "- ! is the universal quantifier\n",
    "- ? is the existential quantifier\n",
    "- variables are denoted with capital letters\n",
    "- func(C) is a function with variable C\n",
    "- => is the implication operator\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NEGATION\n",
    "- <=> is EQUIVALENCE\n",
    "- = is EQUALITY\n",
    "- != is INEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axiom:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",axiom,\"+str(self.statement)+\").\"\n",
    "\n",
    "class Conjecture:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",conjecture,\"+str(self.statement)+\").\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theorum = str(Axiom(\"1\",\"b\"))+str(Axiom(\"2\",\"(a&b)=>b\"))+str(Axiom(\"3\",\"b=>c\"))+str(Conjecture(\"c1\",\"c\"))\n",
    "\n",
    "print(str(Axiom(\"1\",\"a\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#needs E, can't run on colab\n",
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "    f.write(theorum)\n",
    "\n",
    "result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "output = result.stdout.decode()\n",
    "\n",
    "if result.returncode == 0:\n",
    "    #proof found\n",
    "    print(output)\n",
    "    pass\n",
    "\n",
    "elif result.returncode == 1:\n",
    "    #proof not found\n",
    "    print(output)\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    #something else happened\n",
    "    print(result)\n",
    "    raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the proof output.\n",
    "Todo: get rid of unnecessary info like filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_result = \"\"\n",
    "for line in output.split('\\n'):\n",
    "    if len(line) > 0 and line[0] == '#':\n",
    "        pass\n",
    "    else:\n",
    "        line = line.replace(' ','')\n",
    "        print(line)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate expressions using:\n",
    "- and &\n",
    "- or |\n",
    "- not ~\n",
    "- implies =>\n",
    "- a1,a2,a3 etc for axiom names\n",
    "- c1,c2,c3 etc for conjecture names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_list = ['&','|']\n",
    "\n",
    "original = ['a','b','~a','~b',]\n",
    "prop_names = []\n",
    "\n",
    "for x in original:\n",
    "    prop_names.append(str(x))\n",
    "\n",
    "ops = operation_list\n",
    "new = dict()\n",
    "new2 = list()\n",
    "\n",
    "\n",
    "for name in prop_names:\n",
    "    new[str(name)]=str(name)\n",
    "\n",
    "#i here is the length of the LHS of the axiom names, for example i=0 a=>a, i=1, a&a=>a, i=2 a&a|a=>a \n",
    "for i in range(1):\n",
    "    for var1 in original:\n",
    "        for var2 in prop_names:\n",
    "            for o in ops:\n",
    "                #may need regular expressions here to remove duplicated elements\n",
    "                new[str(var1)+str(o)+str(var2)]=str(var1)+str(o)+str(var2)\n",
    "        \n",
    "    for e in new:\n",
    "        original.append(str(new[e]))\n",
    "\n",
    "for element in new:\n",
    "    for name in prop_names:\n",
    "        result = '('+str(new[element])+\")=>\"+str(name)\n",
    "        new2.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to run this on colab\n",
    "print(len(new2))\n",
    "with open('data.pickle','wb') as f:\n",
    "    pickle.dump(new2,f)\n",
    "\n",
    "with open('data.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "for i in range(10):\n",
    "    print(data[random.randint(0,(len(data))-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = new2\n",
    "conclusions = prop_names\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append(Axiom(str(i),statements[i]))\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append(Conjecture(str(i),conclusions[i]))\n",
    "\n",
    "theorum_list = list()\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        theorum_list.append(str(s)+str(c))\n",
    "\n",
    "\n",
    "#needs E, can't run on colab\n",
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "for t in theorum_list:\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(t))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        #print(output)\n",
    "        found_proofs.append([str(t),result])\n",
    "        pass\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(t),result])\n",
    "        #print(output)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(found_proofs))\n",
    "print(len(unfound_proofs))\n",
    "print(len(found_proofs)+len(unfound_proofs))\n",
    "print(len(theorum_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNF creation\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NOT\n",
    "- CNF -> (Disjunction) & CNF\n",
    "- CNF -> (Disjunction)\n",
    "- Disjunction -> Literal | Disjunction\n",
    "- Disjunction -> Literal\n",
    "- Literal -> ~Variable\n",
    "- Literal -> Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "1806\n"
     ]
    }
   ],
   "source": [
    "def produce_disjunctions(literal_list):\n",
    "    disjunction_dict = dict()\n",
    "    disjunction_dict_old = dict()\n",
    "    disjunction_list = []\n",
    "\n",
    "    for l in literal_list:\n",
    "        disjunction_dict[str(l)]=l\n",
    "        disjunction_dict_old[str(l)]=l\n",
    "\n",
    "    for key in disjunction_dict_old:\n",
    "        for l in literal_list:\n",
    "            disjunction_dict[str(l)+'|'+str(disjunction_dict_old[key])]=str(l)+'|'+str(disjunction_dict_old[key])\n",
    "\n",
    "    for key in disjunction_dict:\n",
    "        disjunction_list.append(disjunction_dict[key])\n",
    "\n",
    "    disjunction_dict = None\n",
    "    disjunction_dict_old = None\n",
    "    \n",
    "    return disjunction_list\n",
    "\n",
    "def produce_cnf(disjunction_list):\n",
    "    cnf_dict_new = dict()\n",
    "    cnf_list_old = []\n",
    "    cnf_list_new = []\n",
    "\n",
    "    for d in disjunction_list:\n",
    "        cnf_list_old.append('('+str(d)+')')\n",
    "        cnf_dict_new['('+str(d)+')']='('+str(d)+')'\n",
    "\n",
    "    for c in cnf_list_old:\n",
    "        for d in disjunction_list:\n",
    "            cnf_dict_new['('+str(d)+')&'+str(c)]='('+str(d)+')&'+str(c)\n",
    "    \n",
    "    for key in cnf_dict_new:\n",
    "        cnf_list_new.append(cnf_dict_new[key])\n",
    "\n",
    "    cnf_list_old = None\n",
    "    cnf_dict_new = None\n",
    "\n",
    "    return cnf_list_new\n",
    "\n",
    "#variable_list = ['a','b','c', 'd', 'e']\n",
    "variable_list = ['a','b','c']\n",
    "literal_list = []\n",
    "disjunction_list = []\n",
    "\n",
    "\n",
    "for var in variable_list:\n",
    "    for i in range(2):\n",
    "        if i % 2 == 0:\n",
    "            literal_list.append(str(var))\n",
    "        else:\n",
    "            literal_list.append('~'+str(var))\n",
    "\n",
    "d_list = produce_disjunctions(literal_list)\n",
    "cnf_list = produce_cnf(d_list)\n",
    "print(len(d_list))\n",
    "print(len(cnf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list()\n",
    "conclusions = list()\n",
    "for e in cnf_list:\n",
    "    statements.append(e)\n",
    "    conclusions.append(e)\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "#add a copy for yourself not in E format\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append(Axiom(str(i),statements[i]))\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append(Conjecture(str(i),conclusions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theorum_list = list()\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        theorum_list.append(str(s)+str(c))\n",
    "\n",
    "#for s1 in statement_list:\n",
    "#    for s2 in statement_list:\n",
    "#        if s1 is not s2:\n",
    "#            for c in conclusion_list:\n",
    "#               theorum_list.append(str(s1)+str(s2)+str(c))\n",
    "\n",
    "#for s1 in statement_list:\n",
    "#    for s2 in statement_list:\n",
    "#        if s1 is not s2:\n",
    "#            for s3 in statement_list:\n",
    "#                if (s3 is not s1) and (s3 is not s2):\n",
    "#                    for c in conclusion_list:\n",
    "#                       theorum_list.append(str(s1)+str(s2)+str(s3)+str(c))\n",
    "\n",
    "#needs E, can't run on colab\n",
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "for t in theorum_list:\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(t))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        #print(output)\n",
    "        found_proofs.append([str(t),result])\n",
    "        pass\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(t),result])\n",
    "        #print(output)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "420\n"
     ]
    }
   ],
   "source": [
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "\n",
    "for i in range(len(cnf_list)):\n",
    "    statement_list.append(Axiom(str(i),cnf_list[i]))\n",
    "for i in range(len(cnf_list)):\n",
    "    conclusion_list.append(Conjecture(str(i),cnf_list[i]))\n",
    "\n",
    "print(len(statement_list))\n",
    "print(len(conclusion_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52368\n",
      "124032\n"
     ]
    }
   ],
   "source": [
    "print(len(found_proofs))\n",
    "print(len(unfound_proofs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no need to run this on colab\n",
    "with open('found.pickle','wb') as f:\n",
    "    pickle.dump(found_proofs,f)\n",
    "\n",
    "with open('found.pickle','rb') as f:\n",
    "    found = pickle.load(f)\n",
    "\n",
    "\n",
    "#no need to run this on colab\n",
    "with open('unfound.pickle','wb') as f:\n",
    "    pickle.dump(unfound_proofs,f)\n",
    "\n",
    "with open('unfound.pickle','rb') as f:\n",
    "    unfound = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fof(368,axiom,(a|~a)&(~a|~b)).fof(131,conjecture,(~b|~a)&(~a|a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=0, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_4, negated_conjecture, (a)).\\n#\\n#cnf(i_0_5, negated_conjecture, (b)).\\n##\\n# Proof found!\\n# SZS status Theorem\\n# SZS output start CNFRefutation\\nfof(131, conjecture, ((~(b)|~(a))&(~(a)|a)), file('f.tptp', 131)).\\nfof(368, axiom, ((a|~(a))&(~(a)|~(b))), file('f.tptp', 368)).\\nfof(c_0_2, negated_conjecture, ~(((~b|~a)&(~a|a))), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[131])])).\\nfof(c_0_3, negated_conjecture, (((a|b)&(~a|b))&((a|a)&(~a|a))), inference(distribute,[status(thm)],[inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_2])])])).\\nfof(c_0_4, plain, ((a|~a)&(~a|~b)), inference(fof_simplification,[status(thm)],[368])).\\ncnf(c_0_5, negated_conjecture, (a|a), inference(split_conjunct,[status(thm)],[c_0_3])).\\nfof(c_0_6, plain, ((a|~a)&(~a|~b)), inference(fof_nnf,[status(thm)],[c_0_4])).\\ncnf(c_0_7, negated_conjecture, (b|~a), inference(split_conjunct,[status(thm)],[c_0_3])).\\ncnf(c_0_8, negated_conjecture, (a), inference(cn,[status(thm)],[c_0_5])).\\ncnf(c_0_9, plain, (~a|~b), inference(split_conjunct,[status(thm)],[c_0_6])).\\ncnf(c_0_10, negated_conjecture, (b), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_7, c_0_8])])).\\ncnf(c_0_11, plain, ($false), inference(cn,[status(thm)],[inference(rw,[status(thm)],[inference(rw,[status(thm)],[c_0_9, c_0_8]), c_0_10])]), ['proof']).\\n# SZS output end CNFRefutation\\n\", stderr=b'')]\n",
      "['fof(343,axiom,(~b)&(a|~b)).fof(198,conjecture,(b|~b)&(a|~a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=0, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_1, plain, (a|~b)).\\n##\\n#cnf(i_0_4, negated_conjecture, (b|~a)).\\n#\\n#cnf(i_0_2, plain, (~b)).\\n#\\n#cnf(i_0_3, negated_conjecture, (a)).\\n\\n# Proof found!\\n# SZS status Theorem\\n# SZS output start CNFRefutation\\nfof(198, conjecture, ((b|~(b))&(a|~(a))), file('f.tptp', 198)).\\nfof(343, axiom, (~(b)&(a|~(b))), file('f.tptp', 343)).\\nfof(c_0_2, negated_conjecture, ~(((b|~b)&(a|~a))), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[198])])).\\nfof(c_0_3, plain, (~b&(a|~b)), inference(fof_simplification,[status(thm)],[343])).\\nfof(c_0_4, negated_conjecture, (((~a|~b)&(a|~b))&((~a|b)&(a|b))), inference(distribute,[status(thm)],[inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_2])])])).\\nfof(c_0_5, plain, (~b&(a|~b)), inference(fof_nnf,[status(thm)],[c_0_3])).\\ncnf(c_0_6, negated_conjecture, (a|b), inference(split_conjunct,[status(thm)],[c_0_4])).\\ncnf(c_0_7, plain, (~b), inference(split_conjunct,[status(thm)],[c_0_5])).\\ncnf(c_0_8, negated_conjecture, (b|~a), inference(split_conjunct,[status(thm)],[c_0_4])).\\ncnf(c_0_9, negated_conjecture, (a), inference(sr,[status(thm)],[c_0_6, c_0_7])).\\ncnf(c_0_10, negated_conjecture, ($false), inference(sr,[status(thm)],[inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_8, c_0_9])]), c_0_7]), ['proof']).\\n# SZS output end CNFRefutation\\n\", stderr=b'')]\n",
      "['fof(156,axiom,(a|~b)&(b|a)).fof(7,conjecture,(~b|a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=0, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_4, negated_conjecture, (b)).\\n#\\n#cnf(i_0_2, plain, (a)).\\n##\\n# Proof found!\\n# SZS status Theorem\\n# SZS output start CNFRefutation\\nfof(156, axiom, ((a|~(b))&(b|a)), file('f.tptp', 156)).\\nfof(7, conjecture, (~(b)|a), file('f.tptp', 7)).\\nfof(c_0_2, plain, ((a|~b)&(b|a)), inference(fof_simplification,[status(thm)],[156])).\\nfof(c_0_3, negated_conjecture, ~((~b|a)), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[7])])).\\nfof(c_0_4, plain, ((a|~b)&(b|a)), inference(fof_nnf,[status(thm)],[c_0_2])).\\nfof(c_0_5, negated_conjecture, (b&~a), inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_3])])).\\ncnf(c_0_6, plain, (a|~b), inference(split_conjunct,[status(thm)],[c_0_4])).\\ncnf(c_0_7, negated_conjecture, (b), inference(split_conjunct,[status(thm)],[c_0_5])).\\ncnf(c_0_8, negated_conjecture, (~a), inference(split_conjunct,[status(thm)],[c_0_5])).\\ncnf(c_0_9, plain, (a), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_6, c_0_7])])).\\ncnf(c_0_10, negated_conjecture, ($false), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_8, c_0_9])]), ['proof']).\\n# SZS output end CNFRefutation\\n\", stderr=b'')]\n",
      "['fof(79,axiom,(~b|~b)&(b)).fof(383,conjecture,(~b)&(b|~b)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=0, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_1, plain, (b)).\\n##\\n# Proof found!\\n# SZS status ContradictoryAxioms\\n# SZS output start CNFRefutation\\nfof(79, axiom, ((~(b)|~(b))&b), file('f.tptp', 79)).\\nfof(c_0_1, plain, (~b&b), inference(fof_simplification,[status(thm)],[79])).\\nfof(c_0_2, plain, (~b&b), inference(fof_nnf,[status(thm)],[c_0_1])).\\ncnf(c_0_3, plain, (~b), inference(split_conjunct,[status(thm)],[c_0_2])).\\ncnf(c_0_4, plain, (b), inference(split_conjunct,[status(thm)],[c_0_2])).\\ncnf(c_0_5, plain, ($false), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_3, c_0_4])]), ['proof']).\\n# SZS output end CNFRefutation\\n\", stderr=b'')]\n",
      "['fof(389,axiom,(~a|~a)&(b|~b)).fof(335,conjecture,(~b|b)&(~b|b)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=0, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_4, negated_conjecture, (b)).\\n#\\n#cnf(i_0_2, plain, (~a)).\\n#\\n# Proof found!\\n# SZS status Theorem\\n# SZS output start CNFRefutation\\nfof(335, conjecture, ((~(b)|b)&(~(b)|b)), file('f.tptp', 335)).\\nfof(c_0_1, negated_conjecture, ~((~b|b)), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[335])])).\\nfof(c_0_2, negated_conjecture, (b&~b), inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_1])])).\\ncnf(c_0_3, negated_conjecture, (~b), inference(split_conjunct,[status(thm)],[c_0_2])).\\ncnf(c_0_4, negated_conjecture, (b), inference(split_conjunct,[status(thm)],[c_0_2])).\\ncnf(c_0_5, negated_conjecture, ($false), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_3, c_0_4])]), ['proof']).\\n# SZS output end CNFRefutation\\n\", stderr=b'')]\n",
      "\n",
      "['fof(277,axiom,(~a|~b)&(a|b)).fof(253,conjecture,(~a|b)&(~b|~a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=1, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_5, negated_conjecture, (a)).\\n###\\n#cnf(i_0_2, plain, (~b)).\\n#\\n# No proof found!\\n# SZS status CounterSatisfiable\\n# SZS output start Saturation\\nfof(253, conjecture, ((~(a)|b)&(~(b)|~(a))), file('f.tptp', 253)).\\nfof(277, axiom, ((~(a)|~(b))&(a|b)), file('f.tptp', 277)).\\nfof(c_0_2, negated_conjecture, ~(((~a|b)&(~b|~a))), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[253])])).\\nfof(c_0_3, plain, ((~a|~b)&(a|b)), inference(fof_simplification,[status(thm)],[277])).\\nfof(c_0_4, negated_conjecture, (((b|a)&(a|a))&((b|~b)&(a|~b))), inference(distribute,[status(thm)],[inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_2])])])).\\nfof(c_0_5, plain, ((~a|~b)&(a|b)), inference(fof_nnf,[status(thm)],[c_0_3])).\\ncnf(c_0_6, negated_conjecture, (a|a), inference(split_conjunct,[status(thm)],[c_0_4])).\\ncnf(c_0_7, plain, (~a|~b), inference(split_conjunct,[status(thm)],[c_0_5])).\\ncnf(c_0_8, negated_conjecture, (a), inference(cn,[status(thm)],[c_0_6]), ['final']).\\ncnf(c_0_9, plain, (~b), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_7, c_0_8])]), ['final']).\\n# SZS output end Saturation\\n\", stderr=b'')]\n",
      "['fof(54,axiom,(b|b)&(~a)).fof(413,conjecture,(~a|b)&(~b|~b)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=1, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_2, plain, (b)).\\n##\\n#cnf(i_0_1, plain, (~a)).\\n\\n# No proof found!\\n# SZS status CounterSatisfiable\\n# SZS output start Saturation\\nfof(54, axiom, ((b|b)&~(a)), file('f.tptp', 54)).\\nfof(c_0_1, plain, (b&~a), inference(fof_simplification,[status(thm)],[54])).\\nfof(c_0_2, plain, (b&~a), inference(fof_nnf,[status(thm)],[c_0_1])).\\ncnf(c_0_3, plain, (~a), inference(split_conjunct,[status(thm)],[c_0_2]), ['final']).\\ncnf(c_0_4, plain, (b), inference(split_conjunct,[status(thm)],[c_0_2]), ['final']).\\n# SZS output end Saturation\\n\", stderr=b'')]\n",
      "['fof(220,axiom,(a)&(b|~a)).fof(59,conjecture,(~b|~b)&(~a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=1, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_2, plain, (a)).\\n#\\n#cnf(i_0_1, plain, (b)).\\n#\\n# No proof found!\\n# SZS status CounterSatisfiable\\n# SZS output start Saturation\\nfof(220, axiom, (a&(b|~(a))), file('f.tptp', 220)).\\nfof(c_0_1, plain, (a&(b|~a)), inference(fof_simplification,[status(thm)],[220])).\\nfof(c_0_2, plain, (a&(b|~a)), inference(fof_nnf,[status(thm)],[c_0_1])).\\ncnf(c_0_3, plain, (b|~a), inference(split_conjunct,[status(thm)],[c_0_2])).\\ncnf(c_0_4, plain, (a), inference(split_conjunct,[status(thm)],[c_0_2]), ['final']).\\ncnf(c_0_5, plain, (b), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_3, c_0_4])]), ['final']).\\n# SZS output end Saturation\\n\", stderr=b'')]\n",
      "['fof(112,axiom,(a|b)&(a|a)).fof(22,conjecture,(b)&(a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=1, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_1, plain, (a)).\\n##\\n#cnf(i_0_3, negated_conjecture, (~b)).\\n\\n# No proof found!\\n# SZS status CounterSatisfiable\\n# SZS output start Saturation\\nfof(22, conjecture, (b&a), file('f.tptp', 22)).\\nfof(112, axiom, ((a|b)&(a|a)), file('f.tptp', 112)).\\nfof(c_0_2, negated_conjecture, ~((b&a)), inference(assume_negation,[status(cth)],[22])).\\nfof(c_0_3, negated_conjecture, (~b|~a), inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_2])])).\\nfof(c_0_4, plain, ((a|b)&a), inference(fof_simplification,[status(thm)],[112])).\\ncnf(c_0_5, negated_conjecture, (~b|~a), inference(split_conjunct,[status(thm)],[c_0_3])).\\ncnf(c_0_6, plain, (a), inference(split_conjunct,[status(thm)],[c_0_4]), ['final']).\\ncnf(c_0_7, negated_conjecture, (~b), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_5, c_0_6])]), ['final']).\\n# SZS output end Saturation\\n\", stderr=b'')]\n",
      "['fof(249,axiom,(~a|~a)&(~b|~a)).fof(122,conjecture,(b)&(~a|a)).', CompletedProcess(args=['/home/anmarch/source/eprover/PROVER/eprover', '--proof-object', 'f.tptp'], returncode=1, stdout=b\"# Initializing proof state\\n# Scanning for AC axioms\\n#\\n#cnf(i_0_4, negated_conjecture, (a|~b)).\\n#\\n#cnf(i_0_2, plain, (~a)).\\n#\\n#cnf(i_0_5, negated_conjecture, (~b)).\\n##\\n# No proof found!\\n# SZS status CounterSatisfiable\\n# SZS output start Saturation\\nfof(249, axiom, ((~(a)|~(a))&(~(b)|~(a))), file('f.tptp', 249)).\\nfof(122, conjecture, (b&(~(a)|a)), file('f.tptp', 122)).\\nfof(c_0_2, plain, (~a&(~b|~a)), inference(fof_simplification,[status(thm)],[249])).\\nfof(c_0_3, negated_conjecture, ~((b&(~a|a))), inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[122])])).\\nfof(c_0_4, plain, (~a&(~b|~a)), inference(fof_nnf,[status(thm)],[c_0_2])).\\nfof(c_0_5, negated_conjecture, ((a|~b)&(~a|~b)), inference(distribute,[status(thm)],[inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[c_0_3])])])).\\ncnf(c_0_6, plain, (~a), inference(split_conjunct,[status(thm)],[c_0_4]), ['final']).\\ncnf(c_0_7, negated_conjecture, (a|~b), inference(split_conjunct,[status(thm)],[c_0_5])).\\ncnf(c_0_8, negated_conjecture, (~b), inference(pm,[status(thm)],[c_0_6, c_0_7]), ['final']).\\n# SZS output end Saturation\\n\", stderr=b'')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(found[random.randint(0,(len(found))-1)])\n",
    "print()\n",
    "for i in range(5):\n",
    "    print(unfound[random.randint(0,(len(unfound))-1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fof(368,axiom,(a|~a)&(~a|~b)).fof(131,conjecture,(~b|~a)&(~a|a)).\n",
    "\n",
    "should be \n",
    "\n",
    "(a|~a)&(~a|~b) => (~b|~a)&(~a|a)\n",
    "\n",
    "token list:\n",
    "(\n",
    ")\n",
    "a\n",
    "|\n",
    "~\n",
    "b\n",
    "=>\n",
    "\n",
    "write the tokenization, input that into a LSTM to classify theorums"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
