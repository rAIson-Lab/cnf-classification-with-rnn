{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import subprocess\n",
    "import re\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPTP Formatting\n",
    "fof(name,formula_type,statement)\n",
    "- name is the name of the formula\n",
    "- formula_type is either axiom or conjecture, for our purposes.\n",
    "- Axioms are facts\n",
    "- Conjectures are what we want to prove/disprove\n",
    "\n",
    "\n",
    "Extra TPTP notes:\n",
    "- ! is the universal quantifier\n",
    "- ? is the existential quantifier\n",
    "- variables are denoted with capital letters\n",
    "- func(C) is a function with variable C\n",
    "- => is the implication operator\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NEGATION\n",
    "- <=> is EQUIVALENCE\n",
    "- = is EQUALITY\n",
    "- != is INEQUALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Axiom:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",axiom,\"+str(self.statement)+\").\"\n",
    "\n",
    "class Conjecture:\n",
    "    def __init__(self,name,statement):\n",
    "        self.name = name\n",
    "        self.statement = statement\n",
    "    def __str__(self):\n",
    "        return \"fof(\"+str(self.name)+\",conjecture,\"+str(self.statement)+\").\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fof(1,axiom,a).\n"
     ]
    }
   ],
   "source": [
    "theorum = str(Axiom(\"1\",\"b\"))+str(Axiom(\"2\",\"(a&b)=>b\"))+str(Axiom(\"3\",\"b=>c\"))+str(Conjecture(\"c1\",\"c\"))\n",
    "\n",
    "print(str(Axiom(\"1\",\"a\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Initializing proof state\n",
      "# Scanning for AC axioms\n",
      "#\n",
      "#cnf(i_0_1, plain, (b)).\n",
      "#\n",
      "#cnf(i_0_3, plain, (c)).\n",
      "#\n",
      "# Proof found!\n",
      "# SZS status Theorem\n",
      "# SZS output start CNFRefutation\n",
      "fof(c1, conjecture, c, file('f.tptp', c1)).\n",
      "fof(3, axiom, (b=>c), file('f.tptp', 3)).\n",
      "fof(1, axiom, b, file('f.tptp', 1)).\n",
      "fof(c_0_3, negated_conjecture, ~c, inference(fof_simplification,[status(thm)],[inference(assume_negation,[status(cth)],[c1])])).\n",
      "fof(c_0_4, plain, (~b|c), inference(fof_nnf,[status(thm)],[inference(fof_nnf,[status(thm)],[3])])).\n",
      "fof(c_0_5, negated_conjecture, ~c, inference(fof_nnf,[status(thm)],[c_0_3])).\n",
      "cnf(c_0_6, plain, (c|~b), inference(split_conjunct,[status(thm)],[c_0_4])).\n",
      "cnf(c_0_7, plain, (b), inference(split_conjunct,[status(thm)],[1])).\n",
      "cnf(c_0_8, negated_conjecture, (~c), inference(split_conjunct,[status(thm)],[c_0_5])).\n",
      "cnf(c_0_9, plain, (c), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_6, c_0_7])])).\n",
      "cnf(c_0_10, negated_conjecture, ($false), inference(cn,[status(thm)],[inference(rw,[status(thm)],[c_0_8, c_0_9])]), ['proof']).\n",
      "# SZS output end CNFRefutation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#needs E, can't run on colab\n",
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "    f.write(theorum)\n",
    "\n",
    "result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "output = result.stdout.decode()\n",
    "\n",
    "if result.returncode == 0:\n",
    "    #proof found\n",
    "    print(output)\n",
    "    pass\n",
    "\n",
    "elif result.returncode == 1:\n",
    "    #proof not found\n",
    "    print(output)\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    #something else happened\n",
    "    print(result)\n",
    "    raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the proof output.\n",
    "Todo: get rid of unnecessary info like filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fof(c1,conjecture,c,file('f.tptp',c1)).\n"
     ]
    }
   ],
   "source": [
    "parsed_result = \"\"\n",
    "for line in output.split('\\n'):\n",
    "    if len(line) > 0 and line[0] == '#':\n",
    "        pass\n",
    "    else:\n",
    "        line = line.replace(' ','')\n",
    "        print(line)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate expressions using:\n",
    "- and &\n",
    "- or |\n",
    "- not ~\n",
    "- implies =>\n",
    "- a1,a2,a3 etc for axiom names\n",
    "- c1,c2,c3 etc for conjecture names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_list = ['&','|']\n",
    "\n",
    "original = ['a','b','~a','~b',]\n",
    "prop_names = []\n",
    "\n",
    "for x in original:\n",
    "    prop_names.append(str(x))\n",
    "\n",
    "ops = operation_list\n",
    "new = dict()\n",
    "new2 = list()\n",
    "\n",
    "\n",
    "for name in prop_names:\n",
    "    new[str(name)]=str(name)\n",
    "\n",
    "#i here is the length of the LHS of the axiom names, for example i=0 a=>a, i=1, a&a=>a, i=2 a&a|a=>a \n",
    "for i in range(1):\n",
    "    for var1 in original:\n",
    "        for var2 in prop_names:\n",
    "            for o in ops:\n",
    "                #may need regular expressions here to remove duplicated elements\n",
    "                new[str(var1)+str(o)+str(var2)]=str(var1)+str(o)+str(var2)\n",
    "        \n",
    "    for e in new:\n",
    "        original.append(str(new[e]))\n",
    "\n",
    "for element in new:\n",
    "    for name in prop_names:\n",
    "        result = '('+str(new[element])+\")=>\"+str(name)\n",
    "        new2.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "(~b|~b)=>~a\n",
      "(b&b)=>~b\n",
      "(~b)=>a\n",
      "(~b|~b)=>b\n",
      "(~a)=>~b\n",
      "(b|~a)=>~b\n",
      "(~a&b)=>b\n",
      "(~b|~b)=>~a\n",
      "(b)=>b\n",
      "(a)=>b\n"
     ]
    }
   ],
   "source": [
    "#no need to run this on colab\n",
    "print(len(new2))\n",
    "with open('data.pickle','wb') as f:\n",
    "    pickle.dump(new2,f)\n",
    "\n",
    "with open('data.pickle','rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "for i in range(10):\n",
    "    print(data[random.randint(0,(len(data))-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = new2\n",
    "conclusions = prop_names\n",
    "\n",
    "statement_list = list()\n",
    "conclusion_list = list()\n",
    "\n",
    "\n",
    "for i in range(len(statements)):\n",
    "    statement_list.append(Axiom(str(i),statements[i]))\n",
    "for i in range(len(conclusions)):\n",
    "    conclusion_list.append(Conjecture(str(i),conclusions[i]))\n",
    "\n",
    "theorum_list = list()\n",
    "for s in statement_list:\n",
    "    for c in conclusion_list:\n",
    "        theorum_list.append(str(s)+str(c))\n",
    "\n",
    "\n",
    "#needs E, can't run on colab\n",
    "file_path = \"f.tptp\"\n",
    "eprover_path = \"/home/anmarch/source/eprover/PROVER/eprover\"\n",
    "found_proofs = list()\n",
    "unfound_proofs = list()\n",
    "for t in theorum_list:\n",
    "    with io.open(file_path,'w',encoding='utf-8') as f:\n",
    "        f.write(str(t))\n",
    "\n",
    "    result = subprocess.run([eprover_path, \"--proof-object\", str(file_path)], capture_output=True)\n",
    "    output = result.stdout.decode()\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        #proof found\n",
    "        #print(output)\n",
    "        found_proofs.append([str(t),result])\n",
    "        pass\n",
    "\n",
    "    elif result.returncode == 1:\n",
    "        #proof not found\n",
    "        unfound_proofs.append([str(t),result])\n",
    "        #print(output)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        #something else happened\n",
    "        print(result)\n",
    "        raise Exception(\"Something unexpected occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "532\n",
      "576\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "print(len(found_proofs))\n",
    "print(len(unfound_proofs))\n",
    "print(len(found_proofs)+len(unfound_proofs))\n",
    "print(len(theorum_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNF creation\n",
    "- & is AND\n",
    "- | is OR\n",
    "- ~ is NOT\n",
    "- CNF -> (Disjunction) & CNF\n",
    "- CNF -> (Disjunction)\n",
    "- Disjunction -> Literal | Disjunction\n",
    "- Disjunction -> Literal\n",
    "- Literal -> ~Variable\n",
    "- Literal -> Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = ['a','b','c']\n",
    "literal_list = []\n",
    "\n",
    "def produce_disjunctions(literal_list):\n",
    "    disjunction_list = []\n",
    "    disjunction_list_old = []\n",
    "\n",
    "    for l in literal_list:\n",
    "        disjunction_list_old.append(l)\n",
    "        disjunction_list.append(l)\n",
    "\n",
    "    for d in disjunction_list_old:\n",
    "        for l in literal_list:\n",
    "            disjunction_list.append(str(l)+'|'+str(d))\n",
    "\n",
    "    return disjunction_list\n",
    "\n",
    "def produce_cnf(disjunction_list):\n",
    "    cnf_list_new = []\n",
    "    cnf_list_old = []\n",
    "\n",
    "    for d in disjunction_list:\n",
    "        cnf_list_old.append('('+str(d)+')')\n",
    "        cnf_list_new.append('('+str(d)+')')\n",
    "\n",
    "    for c in cnf_list_old:\n",
    "        for d in disjunction_list:\n",
    "            cnf_list_new.append('('+str(d)+')&'+str(c))\n",
    "\n",
    "    return cnf_list_new\n",
    "\n",
    "\n",
    "for var in variable_list:\n",
    "    for i in range(2):\n",
    "        if i % 2 == 0:\n",
    "            literal_list.append(str(var))\n",
    "        else:\n",
    "            literal_list.append('~'+str(var))\n",
    "\n",
    "d_list = produce_disjunctions(literal_list)\n",
    "cnf_list = produce_cnf(d_list)\n",
    "\n",
    "d_list2 = produce_disjunctions(d_list)\n",
    "cnf_list2 = produce_cnf(d_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263442\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
